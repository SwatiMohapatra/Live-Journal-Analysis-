{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ba9b74",
   "metadata": {},
   "source": [
    "# Selecting Random Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b1c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megha\\AppData\\Local\\Temp\\ipykernel_3532\\2456383380.py:15: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  selected_nodes = random.sample(all_nodes, 500)\n"
     ]
    }
   ],
   "source": [
    "# #Updated filtering\n",
    "# import random\n",
    "\n",
    "# # Path to the original dataset\n",
    "# file_path = 'Top 5000 communities.txt'\n",
    "\n",
    "# # Read all nodes from the file\n",
    "# all_nodes = set()\n",
    "# with open(file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         nodes = line.strip().split('\\t')\n",
    "#         all_nodes.update(nodes)\n",
    "\n",
    "# # Randomly select 500 unique nodes\n",
    "# selected_nodes = random.sample(all_nodes, 500)\n",
    "\n",
    "# # Filter the communities to include only those that contain all of the 500 selected nodes\n",
    "# selected_communities = []\n",
    "# with open(file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         nodes = line.strip().split('\\t')\n",
    "#         if any(node in selected_nodes for node in nodes):\n",
    "#             selected_communities.append(line.strip())\n",
    "\n",
    "# # Save the filtered communities into a new .txt file\n",
    "# new_file_path = 'Filtered_Top_500_Communities.txt'\n",
    "# with open(new_file_path, 'w') as new_file:\n",
    "#     for community in selected_communities:\n",
    "#         new_file.write(community + '\\n')\n",
    "\n",
    "# # Save the selected nodes into a separate file\n",
    "# selected_nodes_file_path = 'Selected_500_Nodes.txt'\n",
    "# with open(selected_nodes_file_path, 'w') as nodes_file:\n",
    "#     for node in selected_nodes:\n",
    "#         nodes_file.write(node + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86106b7",
   "metadata": {},
   "source": [
    "# Selecting Top 1000 Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbff3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the original dataset\n",
    "file_path = 'Top 5000 communities.txt'\n",
    "\n",
    "# Count the frequency of each node across all communities\n",
    "node_frequency = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        nodes = line.strip().split()\n",
    "        for node in nodes:\n",
    "            if node in node_frequency:\n",
    "                node_frequency[node] += 1\n",
    "            else:\n",
    "                node_frequency[node] = 1\n",
    "\n",
    "top_500_nodes = sorted(node_frequency, key=node_frequency.get, reverse=True)[:1000]\n",
    "\n",
    "\n",
    "modified_communities = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        nodes = line.strip().split()\n",
    "        filtered_nodes = [node for node in nodes if node in top_500_nodes]\n",
    "        if len(filtered_nodes)>=3:  # Only include non-empty communities\n",
    "            modified_communities.append('\\t'.join(filtered_nodes))\n",
    "modified_communities = set(modified_communities)\n",
    "\n",
    "# Save the modified communities into a new .txt file\n",
    "modified_file_path = 'Modified_Top_5000_Communities.txt'\n",
    "with open(modified_file_path, 'w') as modified_file:\n",
    "    for community in modified_communities:\n",
    "        modified_file.write(community + '\\n')\n",
    "\n",
    "# Save the top 500 nodes into a separate file\n",
    "top_500_nodes_file_path = 'Top_1000_Nodes.txt'\n",
    "with open(top_500_nodes_file_path, 'w') as nodes_file:\n",
    "    for node in top_500_nodes:\n",
    "        nodes_file.write(node + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d8291",
   "metadata": {},
   "source": [
    "# Modifying edge-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_nodes = top_500_nodes\n",
    "\n",
    "with open('edge_pair.txt', 'r') as file:\n",
    "    edge_pairs = [tuple(map(int, line.split())) for line in file]\n",
    "\n",
    "filtered_edge_pairs = [pair for pair in edge_pairs if pair[0] in important_nodes and pair[1] in important_nodes]\n",
    "\n",
    "with open('filtered_edge_pairs.txt', 'w') as file:\n",
    "    for pair in filtered_edge_pairs:\n",
    "        file.write(f\"{pair[0]}\\t{pair[1]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
